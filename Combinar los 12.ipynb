{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ride_id  rideable_type           started_at             ended_at  \\\n",
      "0  4EAD8F1AD547356B  electric_bike  2023-11-30 21:50:05  2023-11-30 22:13:27   \n",
      "1  6322270563BF5470  electric_bike  2023-11-03 09:44:02  2023-11-03 10:17:15   \n",
      "2  B37BDE091ECA38E0  electric_bike  2023-11-30 11:39:44  2023-11-30 11:40:08   \n",
      "3  CF0CA5DD26E4F90E   classic_bike  2023-11-08 10:01:45  2023-11-08 10:27:05   \n",
      "4  EB8381AA641348DB   classic_bike  2023-11-03 16:20:25  2023-11-03 16:54:25   \n",
      "\n",
      "       start_station_name start_station_id               end_station_name  \\\n",
      "0         Millennium Park            13008  Pine Grove Ave & Waveland Ave   \n",
      "1  Broadway & Sheridan Rd            13323         Broadway & Sheridan Rd   \n",
      "2   State St & Pearson St     TA1307000061          State St & Pearson St   \n",
      "3     Theater on the Lake     TA1308000001            Theater on the Lake   \n",
      "4     Theater on the Lake     TA1308000001            Theater on the Lake   \n",
      "\n",
      "  end_station_id  start_lat  start_lng    end_lat    end_lng member_casual  \n",
      "0   TA1307000150  41.881101 -87.624082  41.949473 -87.646453        member  \n",
      "1          13323  41.952868 -87.650035  41.952833 -87.649993        member  \n",
      "2   TA1307000061  41.897533 -87.628694  41.897448 -87.628722        member  \n",
      "3   TA1308000001  41.926277 -87.630834  41.926277 -87.630834        member  \n",
      "4   TA1308000001  41.926277 -87.630834  41.926277 -87.630834        member  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ruta a la carpeta donde se encuentran los archivos CSV\n",
    "folder_path = os.getcwd() # Esto usa el directorio de trabajo actual\n",
    "\n",
    "# Crear una lista para almacenar los DataFrames\n",
    "all_data = []\n",
    "\n",
    "# Iterar sobre todos los archivos CSV en la carpeta\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Cargar el archivo CSV\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # Añadir el DataFrame a la lista\n",
    "        all_data.append(data)\n",
    "\n",
    "# Unir todos los DataFrames en uno solo\n",
    "combined_data = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame combinado\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora iniciamos con el proceso de limpieza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesito eliminar los registros no valiidos de columans que me van a ser utiles:  ride_id, started_at, ended_at, member_casual\n",
    "\n",
    "Así como eliminar los registros con una duración de viaje inválida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con valores nulos en columnas clave\n",
    "combined_data = combined_data.dropna(subset=['ride_id', 'started_at', 'ended_at', 'member_casual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started_at    7305758\n",
      "ended_at      7305758\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convertir las columnas de fecha a tipo datetime\n",
    "combined_data['started_at'] = pd.to_datetime(combined_data['started_at'], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "combined_data['ended_at'] = pd.to_datetime(combined_data['ended_at'], errors='coerce', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Revisar si hay valores nulos después de la conversión\n",
    "print(combined_data[['started_at', 'ended_at']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la duración del viaje en minutos\n",
    "combined_data['ride_length'] = (combined_data['ended_at'] - combined_data['started_at']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con duración de viaje menor o igual a 0\n",
    "combined_data = combined_data[combined_data['ride_length'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                    0\n",
      "rideable_type              0\n",
      "started_at                 0\n",
      "ended_at                   0\n",
      "start_station_name    721926\n",
      "start_station_id      721926\n",
      "end_station_name      759146\n",
      "end_station_id        759146\n",
      "start_lat                  0\n",
      "start_lng                  0\n",
      "end_lat                 5708\n",
      "end_lng                 5708\n",
      "member_casual              0\n",
      "ride_length                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar los cambios\n",
    "print(combined_data.isnull().sum()) # Verificar si hay valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4.559898e+06\n",
      "mean     1.613407e+01\n",
      "std      6.275758e+01\n",
      "min      1.666667e-02\n",
      "25%      5.100000e+00\n",
      "50%      8.816667e+00\n",
      "75%      1.563333e+01\n",
      "max      1.559933e+03\n",
      "Name: ride_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(combined_data['ride_length'].describe())  # Verificar estadísticas de la duración del viaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id                0.000000\n",
      "rideable_type          0.000000\n",
      "started_at             0.000000\n",
      "ended_at               0.000000\n",
      "start_station_name    15.832065\n",
      "start_station_id      15.832065\n",
      "end_station_name      16.648311\n",
      "end_station_id        16.648311\n",
      "start_lat              0.000000\n",
      "start_lng              0.000000\n",
      "end_lat                0.125178\n",
      "end_lng                0.125178\n",
      "member_casual          0.000000\n",
      "ride_length            0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcular el porcentaje de valores nulos en cada columna\n",
    "null_percentage = combined_data.isnull().mean() * 100\n",
    "\n",
    "# Mostrar el porcentaje de valores nulos\n",
    "print(null_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los porcentajes de datos nulos que representa en las columnas de nombres e ids de las estaciones es de 16%-17% se decidio remplazar los nulos por el termino **Desconocido** \n",
    "\n",
    "Y en el caso de las columnas con la latitud y longuitud se decidio imputar con los valores de la media de las estaciones de finalización, considerando que esto no significaria un gran impacto en los datos, ya que representan unicamrnte el 0.12%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis Méndez\\AppData\\Local\\Temp\\ipykernel_16776\\1510154459.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['start_station_id'].fillna('Desconocido', inplace=True)\n",
      "C:\\Users\\Luis Méndez\\AppData\\Local\\Temp\\ipykernel_16776\\1510154459.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['end_station_id'].fillna('Desconocido', inplace=True)\n",
      "C:\\Users\\Luis Méndez\\AppData\\Local\\Temp\\ipykernel_16776\\1510154459.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['end_lat'].fillna(combined_data['end_lat'].mean(), inplace=True)\n",
      "C:\\Users\\Luis Méndez\\AppData\\Local\\Temp\\ipykernel_16776\\1510154459.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['end_lng'].fillna(combined_data['end_lng'].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Imputar valores nulos para las estaciones con un valor de \"Desconocido\"\n",
    "combined_data['start_station_name'].fillna('Desconocido', inplace=True)\n",
    "combined_data['end_station_name'].fillna('Desconocido', inplace=True)\n",
    "combined_data['start_station_id'].fillna('Desconocido', inplace=True)\n",
    "combined_data['end_station_id'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Imputar valores nulos en las coordenadas con la media de las estaciones de finalización\n",
    "combined_data['end_lat'].fillna(combined_data['end_lat'].mean(), inplace=True)\n",
    "combined_data['end_lng'].fillna(combined_data['end_lng'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrego algunas columnas derivadas que me serán utiles en el analisis, como el dia de la semana y la hora del día, esto me ayuda a ampliar la busqueda de patrones de uso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna de día de la semana\n",
    "combined_data['day_of_week'] = combined_data['started_at'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar columna de hora del día\n",
    "combined_data['time_of_day'] = combined_data['started_at'].dt.hour.apply(\n",
    "    lambda x: 'Morning' if 6 <= x < 12 else ('Afternoon' if 12 <= x < 18 else ('Evening' if 18 <= x < 24 else 'Night'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           started_at day_of_week time_of_day\n",
      "0 2023-11-30 21:50:05    Thursday     Evening\n",
      "1 2023-11-03 09:44:02      Friday     Morning\n",
      "2 2023-11-30 11:39:44    Thursday     Morning\n",
      "3 2023-11-08 10:01:45   Wednesday     Morning\n",
      "4 2023-11-03 16:20:25      Friday   Afternoon\n"
     ]
    }
   ],
   "source": [
    "# Verificar las nuevas columnas\n",
    "print(combined_data[['started_at', 'day_of_week', 'time_of_day']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificación de la calidad de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ride_id  rideable_type          started_at            ended_at  \\\n",
      "0  4EAD8F1AD547356B  electric_bike 2023-11-30 21:50:05 2023-11-30 22:13:27   \n",
      "1  6322270563BF5470  electric_bike 2023-11-03 09:44:02 2023-11-03 10:17:15   \n",
      "2  B37BDE091ECA38E0  electric_bike 2023-11-30 11:39:44 2023-11-30 11:40:08   \n",
      "3  CF0CA5DD26E4F90E   classic_bike 2023-11-08 10:01:45 2023-11-08 10:27:05   \n",
      "4  EB8381AA641348DB   classic_bike 2023-11-03 16:20:25 2023-11-03 16:54:25   \n",
      "\n",
      "       start_station_name start_station_id               end_station_name  \\\n",
      "0         Millennium Park            13008  Pine Grove Ave & Waveland Ave   \n",
      "1  Broadway & Sheridan Rd            13323         Broadway & Sheridan Rd   \n",
      "2   State St & Pearson St     TA1307000061          State St & Pearson St   \n",
      "3     Theater on the Lake     TA1308000001            Theater on the Lake   \n",
      "4     Theater on the Lake     TA1308000001            Theater on the Lake   \n",
      "\n",
      "  end_station_id  start_lat  start_lng    end_lat    end_lng member_casual  \\\n",
      "0   TA1307000150  41.881101 -87.624082  41.949473 -87.646453        member   \n",
      "1          13323  41.952868 -87.650035  41.952833 -87.649993        member   \n",
      "2   TA1307000061  41.897533 -87.628694  41.897448 -87.628722        member   \n",
      "3   TA1308000001  41.926277 -87.630834  41.926277 -87.630834        member   \n",
      "4   TA1308000001  41.926277 -87.630834  41.926277 -87.630834        member   \n",
      "\n",
      "   ride_length day_of_week time_of_day  \n",
      "0    23.366667    Thursday     Evening  \n",
      "1    33.216667      Friday     Morning  \n",
      "2     0.400000    Thursday     Morning  \n",
      "3    25.333333   Wednesday     Morning  \n",
      "4    34.000000      Friday   Afternoon  \n"
     ]
    }
   ],
   "source": [
    "# Revisar los primeros registros para asegurarse de que las transformaciones se hicieron correctamente\n",
    "print(combined_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id               0\n",
      "rideable_type         0\n",
      "started_at            0\n",
      "ended_at              0\n",
      "start_station_name    0\n",
      "start_station_id      0\n",
      "end_station_name      0\n",
      "end_station_id        0\n",
      "start_lat             0\n",
      "start_lng             0\n",
      "end_lat               0\n",
      "end_lng               0\n",
      "member_casual         0\n",
      "ride_length           0\n",
      "day_of_week           0\n",
      "time_of_day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar cuántos valores nulos quedan\n",
    "print(combined_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar mi Dataframe limpio como un archivo CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "combined_data.to_csv('cleaned_combined_data.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
